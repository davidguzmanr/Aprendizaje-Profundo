{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f55283a",
   "metadata": {},
   "source": [
    "# MobileNet v2 with CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38202998",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47323058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchattacks\n",
    "\n",
    "from utils.evaluation import NormalizationLayer, get_topk_accuracy\n",
    "from utils.evaluation import plot_adversarial, get_same_predictions, get_different_predictions\n",
    "from utils.mobilenetv2 import build_mobilenet_v2\n",
    "from utils.training import train\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0830bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba7dc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38092501",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "Usaré una versión modificada de MobileNet v2 para trabajar con CIFAR10, ver [PyTorch models trained on CIFAR-10 dataset](https://github.com/huyvnphan/PyTorch_CIFAR10). De hecho ya hay una versión pre-entrenada, pero la versión que usa de PyTorch no es compatible con TorchAttacks, de modo que lo más sencillo es entrenarla de cero. La salida tiene puntuaciones no normalizadas, para obtener probabilidades hay que ejecutar un softmax en la salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2447d443",
   "metadata": {},
   "source": [
    "Por la forma en que funciona [Adversarial-Attacks-PyTorch](https://github.com/Harry24k/adversarial-attacks-pytorch) las imágenes de entrada que se le tienen que pasar deben estar en el rango [0,1], pero los modelos pre-entrenados de PyTorch esperan imágenes normalizadas, las cuáles no están en el [0,1]. La forma de resolver ésto es añadiendo una capa de normalización al inicio. Ver [Demo - White Box Attack (Imagenet)](https://nbviewer.jupyter.org/github/Harry24k/adversarial-attacks-pytorch/blob/master/demos/White%20Box%20Attack%20%28ImageNet%29.ipynb) para un ejemplo con los modelos entrenados en ImageNet.\n",
    "\n",
    "Lo único que cambia es que las medias y std serán diferentes, ver [How to use models](https://github.com/huyvnphan/PyTorch_CIFAR10#how-to-use-pretrained-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e158ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La red entrenada es la que usaré para generar los ejemplos adversarios\n",
    "mobilenet_v2 = nn.Sequential(\n",
    "    NormalizationLayer(mean=[0.4914, 0.4822, 0.4465], std=[0.2471, 0.2435, 0.2616]),\n",
    "    build_mobilenet_v2(pretrained=False))\n",
    "\n",
    "mobilenet_v2.load_state_dict(torch.load('models/mobilenet_v2.pt'))\n",
    "mobilenet_v2.eval()\n",
    "\n",
    "# Lo movemos a la GPU, en caso de que haya\n",
    "mobilenet_v2 = mobilenet_v2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2658f808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "Sequential                                         --\n",
       "├─NormalizationLayer: 1-1                          --\n",
       "├─MobileNetV2: 1-2                                 --\n",
       "│    └─Sequential: 2-1                             --\n",
       "│    │    └─ConvBNReLU: 3-1                        928\n",
       "│    │    └─InvertedResidual: 3-2                  896\n",
       "│    │    └─InvertedResidual: 3-3                  5,136\n",
       "│    │    └─InvertedResidual: 3-4                  8,832\n",
       "│    │    └─InvertedResidual: 3-5                  10,000\n",
       "│    │    └─InvertedResidual: 3-6                  14,848\n",
       "│    │    └─InvertedResidual: 3-7                  14,848\n",
       "│    │    └─InvertedResidual: 3-8                  21,056\n",
       "│    │    └─InvertedResidual: 3-9                  54,272\n",
       "│    │    └─InvertedResidual: 3-10                 54,272\n",
       "│    │    └─InvertedResidual: 3-11                 54,272\n",
       "│    │    └─InvertedResidual: 3-12                 66,624\n",
       "│    │    └─InvertedResidual: 3-13                 118,272\n",
       "│    │    └─InvertedResidual: 3-14                 118,272\n",
       "│    │    └─InvertedResidual: 3-15                 155,264\n",
       "│    │    └─InvertedResidual: 3-16                 320,000\n",
       "│    │    └─InvertedResidual: 3-17                 320,000\n",
       "│    │    └─InvertedResidual: 3-18                 473,920\n",
       "│    │    └─ConvBNReLU: 3-19                       412,160\n",
       "│    └─Sequential: 2-2                             --\n",
       "│    │    └─Dropout: 3-20                          --\n",
       "│    │    └─Linear: 3-21                           12,810\n",
       "===========================================================================\n",
       "Total params: 2,236,682\n",
       "Trainable params: 2,236,682\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mobilenet_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356569d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta red es la que entrenaré\n",
    "mobilenet_v2_adversarial = nn.Sequential(\n",
    "    NormalizationLayer(mean=[0.4914, 0.4822, 0.4465], std=[0.2471, 0.2435, 0.2616]),\n",
    "    build_mobilenet_v2(pretrained=False))\n",
    "\n",
    "# Lo movemos a la GPU, en caso de que haya\n",
    "mobilenet_v2_adversarial = mobilenet_v2_adversarial.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd86b6a5",
   "metadata": {},
   "source": [
    "## Dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f5ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Trainset: 50000\n",
      "Testset: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f'Trainset: {len(trainset)}')\n",
    "print(f'Testset: {len(testset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2234f",
   "metadata": {},
   "source": [
    "### Adversarial examples\n",
    "\n",
    "Tomaré 5,000 imágenes de manera aleatoria del conjunto de entrenamiento, posteriormente le aplicaré a cada imagen 4 algoritmos de ataques, por lo que en total tendré al final 20,000 ejemplos adversarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e805d161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       " (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "  array([493, 547, 488, 517, 504, 497, 484, 487, 480, 503])))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = random.sample(range(50000), 5000)\n",
    "imgs = np.array([trainset.__getitem__(i)[0].numpy() for i in indexes])\n",
    "labels = np.array([trainset.__getitem__(i)[1] for i in indexes])\n",
    "\n",
    "len(set(indexes)), np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ced76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_subset = torch.tensor(imgs)\n",
    "labels_subset = torch.tensor(labels)\n",
    "\n",
    "trainset_subset = TensorDataset(imgs_subset, labels_subset)\n",
    "trainloader_subset = DataLoader(trainset_subset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ab1c5",
   "metadata": {},
   "source": [
    "#### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d0f95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Save Progress: 100.00 % / Accuracy: 47.68 % / L2: 0.21692\n",
      "- Save Complete!\n",
      "CPU times: user 7.41 s, sys: 304 ms, total: 7.71 s\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "attack = torchattacks.FGSM(mobilenet_v2, eps=1/255)\n",
    "attack.set_return_type('float') \n",
    "attack.save(trainloader_subset, save_path='models/FGSM_train.pt', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2c0e55",
   "metadata": {},
   "source": [
    "#### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ac86c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Save Progress: 100.00 % / Accuracy: 34.72 % / L2: 0.20776\n",
      "- Save Complete!\n",
      "CPU times: user 15.3 s, sys: 325 ms, total: 15.6 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "attack = torchattacks.PGD(mobilenet_v2, eps=1/255, alpha=1/255, steps=3)\n",
    "attack.set_return_type('float') \n",
    "attack.save(trainloader_subset, save_path='models/PGD_train.pt', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1aaecd",
   "metadata": {},
   "source": [
    "#### MIFGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f8d6e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Save Progress: 100.00 % / Accuracy: 39.72 % / L2: 0.20134\n",
      "- Save Complete!\n",
      "CPU times: user 15.1 s, sys: 417 ms, total: 15.5 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "attack = torchattacks.MIFGSM(mobilenet_v2, eps=1/255, decay=1.0, steps=3)\n",
    "attack.set_return_type('float') \n",
    "attack.save(trainloader_subset, save_path='models/MIFGSM_train.pt', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f877a3",
   "metadata": {},
   "source": [
    "#### OnePixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ddafa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Save Progress: 100.00 % / Accuracy: 81.80 % / L2: 0.85973\n",
      "- Save Complete!\n",
      "CPU times: user 3min 59s, sys: 470 ms, total: 4min\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "attack = torchattacks.OnePixel(mobilenet_v2, pixels=1, steps=5, popsize=20)\n",
    "attack.set_return_type('float') \n",
    "attack.save(trainloader_subset, save_path='models/OnePixel_train.pt', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becef3e1",
   "metadata": {},
   "source": [
    "### Trainset and trainloader\n",
    "\n",
    "Ahora creamos el conjunto de entrenamiento con los ejemplos adversarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce07134",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor(np.array([trainset.__getitem__(i)[0].numpy() for i in range(50000)]))\n",
    "labels = torch.tensor(np.array([trainset.__getitem__(i)[1] for i in range(50000)]))\n",
    "\n",
    "adv_images_FGSM, adv_labels_FGSM = torch.load('models/FGSM_train.pt')\n",
    "adv_images_PGD, adv_labels_PGD = torch.load('models/PGD_train.pt')\n",
    "adv_images_MIFGSM, adv_labels_MIFGSM = torch.load('models/MIFGSM_train.pt')\n",
    "adv_images_OnePixel, adv_labels_OnePixel = torch.load('models/OnePixel_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea37f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_trainset = TensorDataset(torch.cat([images, adv_images_FGSM, adv_images_PGD, adv_images_MIFGSM, adv_images_OnePixel], dim=0),\n",
    "                                     torch.cat([labels, adv_labels_FGSM, adv_labels_PGD, adv_labels_MIFGSM, adv_labels_OnePixel], dim=0))\n",
    "\n",
    "adversarial_trainloader = torch.utils.data.DataLoader(adversarial_trainset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c4615",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bfda692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [01:03<20:00, 63.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E00 loss=[ 93.86,106.52] acc=[66.90,61.85]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:06<18:56, 63.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E01 loss=[ 64.63, 88.68] acc=[77.64,69.41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [03:08<17:49, 62.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E02 loss=[ 48.81, 80.39] acc=[83.57,73.66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [04:11<16:47, 62.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E03 loss=[ 36.52, 73.54] acc=[87.94,75.78]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [05:13<15:36, 62.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E04 loss=[ 28.14, 69.00] acc=[90.85,77.11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [06:10<14:10, 60.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E05 loss=[ 23.09, 68.83] acc=[92.51,78.54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [07:08<12:56, 59.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E06 loss=[ 22.30, 74.21] acc=[92.46,77.33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [08:06<11:51, 59.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E07 loss=[ 16.58, 73.70] acc=[94.49,78.54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [09:05<10:50, 59.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E08 loss=[ 13.22, 71.45] acc=[95.71,78.95]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [10:02<09:45, 58.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E09 loss=[ 15.85, 80.24] acc=[94.58,77.89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [11:01<08:46, 58.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E10 loss=[ 11.35, 75.63] acc=[96.18,79.77]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [11:59<07:48, 58.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E11 loss=[  9.21, 79.85] acc=[96.90,79.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [12:58<06:50, 58.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E12 loss=[  9.45, 81.70] acc=[96.81,79.37]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [13:58<05:53, 58.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E13 loss=[  9.63, 85.95] acc=[96.63,79.33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [14:57<04:55, 59.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E14 loss=[  8.25, 85.79] acc=[97.21,79.54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [15:55<03:55, 58.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E15 loss=[  8.33, 88.68] acc=[97.08,79.51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [16:53<02:55, 58.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E16 loss=[  7.71, 88.18] acc=[97.38,79.86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [17:50<01:56, 58.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E17 loss=[  6.56, 86.12] acc=[97.75,79.52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [18:49<00:58, 58.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E18 loss=[  6.45, 88.08] acc=[97.83,80.50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [19:52<00:00, 59.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E19 loss=[  6.96, 94.48] acc=[97.56,79.74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_hist, acc_hist = train(mobilenet_v2_adversarial, adversarial_trainloader, testloader, lr=1e-3, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2382388a",
   "metadata": {},
   "source": [
    "Guardamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1137d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mobilenet_v2_adversarial.state_dict(), 'models/mobilenet_v2_adversarial.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
