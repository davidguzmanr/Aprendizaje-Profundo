{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfaf19b",
   "metadata": {},
   "source": [
    "# MobileNet v2 with CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f7237",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27feea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchattacks\n",
    "\n",
    "from utils.evaluation import NormalizationLayer, get_topk_accuracy\n",
    "from utils.evaluation import plot_adversarial, get_same_predictions, get_different_predictions\n",
    "from utils.mobilenetv2 import build_mobilenet_v2\n",
    "from utils.training import train\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f8a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9fd654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b4a187",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "Usaré una versión modificada de MobileNet v2 para trabajar con CIFAR10, ver [PyTorch models trained on CIFAR-10 dataset](https://github.com/huyvnphan/PyTorch_CIFAR10). De hecho ya hay una versión pre-entrenada, pero la versión que usa de PyTorch no es compatible con TorchAttacks, de modo que lo más sencillo es entrenarla de cero. La salida tiene puntuaciones no normalizadas, para obtener probabilidades hay que ejecutar un softmax en la salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00da1ec9",
   "metadata": {},
   "source": [
    "Por la forma en que funciona [Adversarial-Attacks-PyTorch](https://github.com/Harry24k/adversarial-attacks-pytorch) las imágenes de entrada que se le tienen que pasar deben estar en el rango [0,1], pero los modelos pre-entrenados de PyTorch esperan imágenes normalizadas, las cuáles no están en el [0,1]. La forma de resolver ésto es añadiendo una capa de normalización al inicio. Ver [Demo - White Box Attack (Imagenet)](https://nbviewer.jupyter.org/github/Harry24k/adversarial-attacks-pytorch/blob/master/demos/White%20Box%20Attack%20%28ImageNet%29.ipynb) para un ejemplo con los modelos entrenados en ImageNet.\n",
    "\n",
    "Lo único que cambia es que las medias y std serán diferentes, ver [How to use models](https://github.com/huyvnphan/PyTorch_CIFAR10#how-to-use-pretrained-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd24f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 = nn.Sequential(\n",
    "    NormalizationLayer(mean=[0.4914, 0.4822, 0.4465], std=[0.2471, 0.2435, 0.2616]),\n",
    "    build_mobilenet_v2(pretrained=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f520879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "Sequential                                         --\n",
       "├─NormalizationLayer: 1-1                          --\n",
       "├─MobileNetV2: 1-2                                 --\n",
       "│    └─Sequential: 2-1                             --\n",
       "│    │    └─ConvBNReLU: 3-1                        928\n",
       "│    │    └─InvertedResidual: 3-2                  896\n",
       "│    │    └─InvertedResidual: 3-3                  5,136\n",
       "│    │    └─InvertedResidual: 3-4                  8,832\n",
       "│    │    └─InvertedResidual: 3-5                  10,000\n",
       "│    │    └─InvertedResidual: 3-6                  14,848\n",
       "│    │    └─InvertedResidual: 3-7                  14,848\n",
       "│    │    └─InvertedResidual: 3-8                  21,056\n",
       "│    │    └─InvertedResidual: 3-9                  54,272\n",
       "│    │    └─InvertedResidual: 3-10                 54,272\n",
       "│    │    └─InvertedResidual: 3-11                 54,272\n",
       "│    │    └─InvertedResidual: 3-12                 66,624\n",
       "│    │    └─InvertedResidual: 3-13                 118,272\n",
       "│    │    └─InvertedResidual: 3-14                 118,272\n",
       "│    │    └─InvertedResidual: 3-15                 155,264\n",
       "│    │    └─InvertedResidual: 3-16                 320,000\n",
       "│    │    └─InvertedResidual: 3-17                 320,000\n",
       "│    │    └─InvertedResidual: 3-18                 473,920\n",
       "│    │    └─ConvBNReLU: 3-19                       412,160\n",
       "│    └─Sequential: 2-2                             --\n",
       "│    │    └─Dropout: 3-20                          --\n",
       "│    │    └─Linear: 3-21                           12,810\n",
       "===========================================================================\n",
       "Total params: 2,236,682\n",
       "Trainable params: 2,236,682\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mobilenet_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d87db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo movemos a la GPU, en caso de que haya\n",
    "mobilenet_v2 = mobilenet_v2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7142f73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4590,  0.1412,  0.0520,  0.2391, -0.0676,  0.0619, -0.0529, -0.1412,\n",
       "         -0.0436,  0.0306]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, 3, 32, 32).to(device)\n",
    "mobilenet_v2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0b1f8",
   "metadata": {},
   "source": [
    "## Dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43631721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Trainset: 50000\n",
      "Testset: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f'Trainset: {len(trainset)}')\n",
    "print(f'Testset: {len(testset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a2dce",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aca8bba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:43<13:50, 43.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E00 loss=[111.59,117.64] acc=[59.66,57.26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:27<13:11, 43.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E01 loss=[ 82.77, 95.32] acc=[70.84,66.80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:11<12:28, 44.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E02 loss=[ 68.56, 82.31] acc=[76.25,71.63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:56<11:45, 44.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E03 loss=[ 52.32, 71.46] acc=[81.82,75.50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [03:40<11:00, 44.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E04 loss=[ 43.66, 69.68] acc=[85.15,76.16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [04:23<10:15, 43.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E05 loss=[ 36.78, 65.88] acc=[87.69,77.96]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [05:07<09:29, 43.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E06 loss=[ 30.14, 65.25] acc=[89.79,78.58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [05:51<08:45, 43.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E07 loss=[ 25.31, 62.44] acc=[91.59,79.64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [06:34<08:00, 43.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E08 loss=[ 21.91, 62.78] acc=[92.69,80.22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [07:18<07:17, 43.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E09 loss=[ 19.78, 66.82] acc=[93.08,80.16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [08:02<06:35, 43.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E10 loss=[ 15.28, 65.24] acc=[94.90,80.69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [08:46<05:51, 43.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E11 loss=[ 12.54, 69.05] acc=[95.74,80.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [09:31<05:08, 44.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E12 loss=[ 14.78, 74.32] acc=[94.69,79.95]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [10:16<04:26, 44.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E13 loss=[ 12.14, 75.67] acc=[95.83,81.06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [11:00<03:41, 44.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E14 loss=[  9.14, 73.80] acc=[96.93,81.05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [11:44<02:57, 44.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E15 loss=[  9.86, 76.11] acc=[96.65,80.86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [12:28<02:12, 44.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E16 loss=[  9.45, 77.78] acc=[96.69,81.04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [13:12<01:28, 44.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E17 loss=[  9.30, 81.76] acc=[96.78,81.15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [13:56<00:44, 44.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E18 loss=[  7.76, 80.52] acc=[97.33,81.29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [14:41<00:00, 44.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E19 loss=[  8.32, 81.60] acc=[97.07,81.29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_hist, acc_hist = train(mobilenet_v2, trainloader, testloader, lr=1e-3, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f929f3aa",
   "metadata": {},
   "source": [
    "Guardamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e415e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mobilenet_v2.state_dict(), 'models/mobilenet_v2.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
